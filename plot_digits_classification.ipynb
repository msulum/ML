{"metadata":{"orig_nbformat":4,"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%matplotlib inline","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n# Recognizing hand-written digits\n\nThis example shows how scikit-learn can be used to recognize images of\nhand-written digits, from 0-9.\n","metadata":{}},{"cell_type":"code","source":"# Author: Gael Varoquaux <gael dot varoquaux at normalesup dot org>\n# License: BSD 3 clause\n\n# Standard scientific Python imports\nimport matplotlib.pyplot as plt\n\n# Import datasets, classifiers and performance metrics\nfrom sklearn import datasets, svm, metrics\nfrom sklearn.model_selection import train_test_split\n\nfrom numpy.fft import fft2, ifft2, fftshift, ifftshift\nimport numpy as np","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Digits dataset\n\nThe digits dataset consists of 8x8\npixel images of digits. The ``images`` attribute of the dataset stores\n8x8 arrays of grayscale values for each image. We will use these arrays to\nvisualize the first 4 images. The ``target`` attribute of the dataset stores\nthe digit each image represents and this is included in the title of the 4\nplots below.\n\nNote: if we were working from image files (e.g., 'png' files), we would load\nthem using :func:`matplotlib.pyplot.imread`.\n\n","metadata":{}},{"cell_type":"code","source":"digits = datasets.load_digits()\n\n_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\nfor ax, image, label in zip(axes, digits.images, digits.target):\n    ax.set_axis_off()\n    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n    ax.set_title(\"Training: %i\" % label)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 720x216 with 4 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"def display_2(im_1, title_1, im_2, title_2):\n    \"\"\"\n    Displays two images side by side; typically, an image and its Fourier transform.\n    \"\"\"\n    plt.figure(figsize=(12,6))                    # Rectangular blackboard\n    plt.subplot(1,2,1) ; plt.title(title_1)       # 1x2 waffle plot, 1st cell\n    plt.imshow(im_1, cmap=\"gray\")                 # Auto-equalization\n    plt.subplot(1,2,2) ; plt.title(title_2)       # 1x2 waffle plot, 2nd cell\n    plt.imshow(im_2, cmap=\"gray\", vmin=-7, vmax=15)       ","metadata":{"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def Fourier_bandpass(fI, fmin, fmax) :\n    \"\"\"\n    Truncates a Fourier Transform fI, before reconstructing a bandpassed image.\n    \"\"\"\n    Y, X = np.mgrid[:fI.shape[0], :fI.shape[1]]  # Horizontal and vertical gradients\n    radius = (X - fI.shape[0]/2) ** 2 \\\n           + (Y - fI.shape[1]/2) ** 2        # Squared distance to the middle point\n    radius = ifftshift( np.sqrt(radius) )    # Reshape to be fft-compatible\n\n    \n    fI_band = fI.copy()               # Create a copy of the Fourier transform\n    fI_band[ radius <=fmin ] = 0      # Remove all the low frequencies\n    fI_band[ radius > fmax ] = 0      # Remove all the high frequencies\n    I_band = np.real(ifft2(fI_band))  # Invert the new transform...\n\n    #display_2( I_band, \"Image\",          # And display\n               #fftshift( np.log(1e-7 + abs(fI_band)) ), \"Fourier Transform\" )\n    print(I_band)","metadata":{"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\nfor ax, image, label in zip(axes, digits.images, digits.target):\n    ax.set_axis_off()\n    image_fft = fft2(image)\n    Fourier_bandpass(image_fft, 0, 50)","metadata":{"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"[[-4.59375 -4.59375  0.40625  8.40625  4.40625 -3.59375 -4.59375 -4.59375]\n [-4.59375 -4.59375  8.40625 10.40625  5.40625 10.40625  0.40625 -4.59375]\n [-4.59375 -1.59375 10.40625 -2.59375 -4.59375  6.40625  3.40625 -4.59375]\n [-4.59375 -0.59375  7.40625 -4.59375 -4.59375  3.40625  3.40625 -4.59375]\n [-4.59375  0.40625  3.40625 -4.59375 -4.59375  4.40625  3.40625 -4.59375]\n [-4.59375 -0.59375  6.40625 -4.59375 -3.59375  7.40625  2.40625 -4.59375]\n [-4.59375 -2.59375  9.40625  0.40625  5.40625  7.40625 -4.59375 -4.59375]\n [-4.59375 -4.59375  1.40625  8.40625  5.40625 -4.59375 -4.59375 -4.59375]]\n[[-4.890625 -4.890625 -4.890625  7.109375  8.109375  0.109375 -4.890625\n  -4.890625]\n [-4.890625 -4.890625 -4.890625  6.109375 11.109375  4.109375 -4.890625\n  -4.890625]\n [-4.890625 -4.890625 -1.890625 10.109375 11.109375  1.109375 -4.890625\n  -4.890625]\n [-4.890625  2.109375 10.109375 11.109375 11.109375 -2.890625 -4.890625\n  -4.890625]\n [-4.890625 -4.890625 -3.890625 11.109375 11.109375 -1.890625 -4.890625\n  -4.890625]\n [-4.890625 -4.890625 -3.890625 11.109375 11.109375  1.109375 -4.890625\n  -4.890625]\n [-4.890625 -4.890625 -3.890625 11.109375 11.109375  1.109375 -4.890625\n  -4.890625]\n [-4.890625 -4.890625 -4.890625  6.109375 11.109375  5.109375 -4.890625\n  -4.890625]]\n[[-5.375 -5.375 -5.375 -1.375  9.625  6.625 -5.375 -5.375]\n [-5.375 -5.375 -2.375 10.625  9.625  8.625 -5.375 -5.375]\n [-5.375 -5.375  2.625  7.625  2.625 10.625 -5.375 -5.375]\n [-5.375 -5.375 -4.375  0.625  9.625  5.625 -5.375 -5.375]\n [-5.375 -4.375  2.625  7.625  9.625 -4.375 -5.375 -5.375]\n [-5.375  3.625 10.625 10.625 -0.375 -5.375 -5.375 -5.375]\n [-5.375 -2.375  7.625 10.625 10.625  5.625 -0.375 -5.375]\n [-5.375 -5.375 -5.375 -2.375  5.625 10.625  3.625 -5.375]]\n[[-4.171875 -4.171875  2.828125 10.828125  8.828125 -3.171875 -4.171875\n  -4.171875]\n [-4.171875  3.828125  8.828125  1.828125 10.828125 -0.171875 -4.171875\n  -4.171875]\n [-4.171875 -2.171875 -3.171875  8.828125  8.828125 -4.171875 -4.171875\n  -4.171875]\n [-4.171875 -4.171875 -2.171875 10.828125  6.828125 -3.171875 -4.171875\n  -4.171875]\n [-4.171875 -4.171875 -4.171875 -3.171875  7.828125  7.828125 -3.171875\n  -4.171875]\n [-4.171875 -4.171875 -4.171875 -4.171875 -3.171875  5.828125  3.828125\n  -4.171875]\n [-4.171875 -4.171875  3.828125 -0.171875  0.828125  9.828125  4.828125\n  -4.171875]\n [-4.171875 -4.171875  2.828125  8.828125  8.828125  4.828125 -4.171875\n  -4.171875]]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 720x216 with 4 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAjwAAACxCAYAAADAvme1AAAAPHRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMHJjMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8w8owxAAAACXBIWXMAAAsTAAALEwEAmpwYAAADJElEQVR4nO3WQQ0AIBDAMMC/50MFIVlaBXtuz8wCACg7vwMAAF4zPABAnuEBAPIMDwCQZ3gAgDzDAwDkGR4AIM/wAAB5hgcAyDM8AECe4QEA8gwPAJBneACAPMMDAOQZHgAgz/AAAHmGBwDIMzwAQJ7hAQDyDA8AkGd4AIA8wwMA5BkeACDP8AAAeYYHAMgzPABAnuEBAPIMDwCQZ3gAgDzDAwDkGR4AIM/wAAB5hgcAyDM8AECe4QEA8gwPAJBneACAPMMDAOQZHgAgz/AAAHmGBwDIMzwAQJ7hAQDyDA8AkGd4AIA8wwMA5BkeACDP8AAAeYYHAMgzPABAnuEBAPIMDwCQZ3gAgDzDAwDkGR4AIM/wAAB5hgcAyDM8AECe4QEA8gwPAJBneACAPMMDAOQZHgAgz/AAAHmGBwDIMzwAQJ7hAQDyDA8AkGd4AIA8wwMA5BkeACDP8AAAeYYHAMgzPABAnuEBAPIMDwCQZ3gAgDzDAwDkGR4AIM/wAAB5hgcAyDM8AECe4QEA8gwPAJBneACAPMMDAOQZHgAgz/AAAHmGBwDIMzwAQJ7hAQDyDA8AkGd4AIA8wwMA5BkeACDP8AAAeYYHAMgzPABAnuEBAPIMDwCQZ3gAgDzDAwDkGR4AIM/wAAB5hgcAyDM8AECe4QEA8gwPAJBneACAPMMDAOQZHgAgz/AAAHmGBwDIMzwAQJ7hAQDyDA8AkGd4AIA8wwMA5BkeACDP8AAAeYYHAMgzPABAnuEBAPIMDwCQZ3gAgDzDAwDkGR4AIM/wAAB5hgcAyDM8AECe4QEA8gwPAJBneACAPMMDAOQZHgAgz/AAAHmGBwDIMzwAQJ7hAQDyDA8AkGd4AIA8wwMA5BkeACDP8AAAeYYHAMgzPABAnuEBAPIMDwCQZ3gAgDzDAwDkGR4AIM/wAAB5hgcAyDM8AECe4QEA8gwPAJBneACAPMMDAOQZHgAgz/AAAHmGBwDIMzwAQJ7hAQDyDA8AkGd4AIA8wwMA5BkeACDP8AAAeYYHAMgzPABAnuEBAPIMDwCQZ3gAgDzDAwDkGR4AIM/wAAB5FxK+BF8iH6EsAAAAAElFTkSuQmCC\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"## Classification\n\nTo apply a classifier on this data, we need to flatten the images, turning\neach 2-D array of grayscale values from shape ``(8, 8)`` into shape\n``(64,)``. Subsequently, the entire dataset will be of shape\n``(n_samples, n_features)``, where ``n_samples`` is the number of images and\n``n_features`` is the total number of pixels in each image.\n\nWe can then split the data into train and test subsets and fit a support\nvector classifier on the train samples. The fitted classifier can\nsubsequently be used to predict the value of the digit for the samples\nin the test subset.\n\n","metadata":{}},{"cell_type":"code","source":"# flatten the images\nn_samples = len(digits.images)\ndata = digits.images.reshape((n_samples, -1))\n\n# Create a classifier: a support vector classifier\nclf = svm.SVC(gamma=0.001)\n\n# Split data into 50% train and 50% test subsets\nX_train, X_test, y_train, y_test = train_test_split(\n    data, digits.target, test_size=0.5, shuffle=False\n)\n\n# Learn the digits on the train subset\nclf.fit(X_train, y_train)\n\n# Predict the value of the digit on the test subset\npredicted = clf.predict(X_test)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Below we visualize the first 4 test samples and show their predicted\ndigit value in the title.\n\n","metadata":{}},{"cell_type":"code","source":"_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\nfor ax, image, prediction in zip(axes, X_test, predicted):\n    ax.set_axis_off()\n    image = image.reshape(8, 8)\n    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n    ax.set_title(f\"Prediction: {prediction}\")","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":":func:`~sklearn.metrics.classification_report` builds a text report showing\nthe main classification metrics.\n\n","metadata":{}},{"cell_type":"code","source":"print(\n    f\"Classification report for classifier {clf}:\\n\"\n    f\"{metrics.classification_report(y_test, predicted)}\\n\"\n)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can also plot a `confusion matrix <confusion_matrix>` of the\ntrue digit values and the predicted digit values.\n\n","metadata":{}},{"cell_type":"code","source":"disp = metrics.ConfusionMatrixDisplay.from_predictions(y_test, predicted)\ndisp.figure_.suptitle(\"Confusion Matrix\")\nprint(f\"Confusion matrix:\\n{disp.confusion_matrix}\")\n\nplt.show()","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]}]}